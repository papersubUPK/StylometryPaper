{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv('/content/ReducedTweets.csv')\n",
        "\n",
        "# NaN values\n",
        "cols_with_nan = dataset.columns[dataset.isna().any()].tolist()\n",
        "for col in cols_with_nan:\n",
        "    if dataset[col].isna().any():\n",
        "        dataset[col] = dataset.groupby('Class')[col].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
        "    else:\n",
        "        print(f\"\")\n",
        "\n",
        "X = dataset.iloc[:, 1:16].values\n",
        "y = dataset.iloc[:, 16].values\n",
        "\n",
        "# Define feature_names\n",
        "feature_names = dataset.columns[1:43]\n",
        "\n",
        "# Split the data into training, testing, and validation sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Define the hyperparameters\n",
        "rf_parameters = {'max_depth': range(1, 5), 'n_estimators': [20, 50, 100]}\n",
        "\n",
        "# Initialize performance metric lists\n",
        "rf_accuracy_scores = []\n",
        "rf_precision_scores = []\n",
        "rf_recall_scores = []\n",
        "rf_f1_scores = []\n",
        "\n",
        "# Initialize a list to store feature importance scores\n",
        "feature_importance_scores = []\n",
        "\n",
        "# Random Forest\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_grid_search = GridSearchCV(rf_classifier, rf_parameters, cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42))\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "rf_best_params = rf_grid_search.best_params_\n",
        "rf_best_model = RandomForestClassifier(random_state=42, **rf_best_params)\n",
        "\n",
        "# Nested cross-validation on the test set\n",
        "for train_index, val_index in StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(X_test, y_test):\n",
        "    X_train_cv, X_val_cv = X_test[train_index], X_test[val_index]\n",
        "    y_train_cv, y_val_cv = y_test[train_index], y_test[val_index]\n",
        "\n",
        "    # Ablation Study\n",
        "    ablation_scores = []\n",
        "    for feature_index in range(X_train_cv.shape[1]):\n",
        "        ablated_X_train = np.delete(X_train_cv, feature_index, axis=1)\n",
        "        ablated_X_val = np.delete(X_val_cv, feature_index, axis=1)\n",
        "        rf_best_model.fit(ablated_X_train, y_train_cv)\n",
        "        rf_predictions = rf_best_model.predict(ablated_X_val)\n",
        "        ablation_scores.append(accuracy_score(y_val_cv, rf_predictions))\n",
        "\n",
        "    # Store feature importance scores\n",
        "    feature_importance_scores.append(ablation_scores)\n",
        "\n",
        "    # Evaluate performance metrics\n",
        "    rf_accuracy_scores.append(np.mean(ablation_scores))\n",
        "    rf_precision_scores.append(precision_score(y_val_cv, rf_predictions))\n",
        "    rf_recall_scores.append(recall_score(y_val_cv, rf_predictions))\n",
        "    rf_f1_scores.append(f1_score(y_val_cv, rf_predictions))\n",
        "\n",
        "# Calculate average performance scores\n",
        "rf_average_accuracy = np.mean(rf_accuracy_scores)\n",
        "rf_average_precision = np.mean(rf_precision_scores)\n",
        "rf_average_recall = np.mean(rf_recall_scores)\n",
        "rf_average_f1 = np.mean(rf_f1_scores)\n",
        "rf_std_accuracy = np.std(rf_accuracy_scores)\n",
        "rf_std_precision = np.std(rf_precision_scores)\n",
        "rf_std_recall = np.std(rf_recall_scores)\n",
        "rf_std_f1 = np.std(rf_f1_scores)\n",
        "\n",
        "# Print the average performance scores\n",
        "print(\"Average Accuracy:\", round(rf_average_accuracy,4))\n",
        "print(\"Standard Deviation Accuracy:\", round(rf_std_accuracy,4))\n",
        "print(\"Average Precision:\", round(rf_average_precision,4))\n",
        "print(\"Standard Deviation Precision:\", round(rf_std_precision,4))\n",
        "print(\"Average Recall:\", round(rf_average_recall,4))\n",
        "print(\"Standard Deviation Recall:\", round(rf_std_recall,4))\n",
        "print(\"Average F1-score:\", round(rf_average_f1,4))\n",
        "print(\"Standard Deviation F1-score:\", round(rf_std_f1,4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcsTfssLikHC",
        "outputId": "d7e4d4f3-6217-4301-c6ef-c9294f829b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8367\n",
            "Standard Deviation Accuracy: 0.0271\n",
            "Average Precision: 0.8672\n",
            "Standard Deviation Precision: 0.0327\n",
            "Average Recall: 0.7933\n",
            "Standard Deviation Recall: 0.0431\n",
            "Average F1-score: 0.8278\n",
            "Standard Deviation F1-score: 0.0283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the best-performing features\n",
        "best_feature_indices_rf = np.argsort(np.mean(feature_importance_scores, axis=0))[::-1]\n",
        "\n",
        "num_features_to_display_rf = 10\n",
        "X_best_features_rf = X[:, best_feature_indices_rf[:num_features_to_display_rf]]\n",
        "\n",
        "# Calculate and print feature importance (average ablation scores) with feature names\n",
        "average_importance_scores_rf = np.mean(feature_importance_scores, axis=0)\n",
        "sorted_indices_rf = np.argsort(average_importance_scores_rf)[::-1]\n",
        "\n",
        "print(\"\\nTop Feature Importance with Scores:\")\n",
        "for i in range(num_features_to_display_rf):\n",
        "    feature_index_rf = sorted_indices_rf[i]\n",
        "    importance_score_rf = round(average_importance_scores_rf[feature_index_rf], 5)\n",
        "    print(f\"{feature_names[feature_index_rf]}: {importance_score_rf}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLYpRj_F9WH4",
        "outputId": "773f1a27-f432-408b-91b2-43f616054687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top Feature Importance with Scores:\n",
            "flesch_reading_ease: 0.84267\n",
            "count_unique_words: 0.84267\n",
            "num_lowercase_words: 0.84133\n",
            "count_words: 0.84067\n",
            "ari: 0.84067\n",
            "total_characters: 0.84\n",
            "smog_index: 0.83933\n",
            "count_numbers: 0.83867\n",
            "gunning_fog: 0.83733\n",
            "coleman_liau_index: 0.83667\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}